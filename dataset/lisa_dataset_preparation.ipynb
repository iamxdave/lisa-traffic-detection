{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e6f2d9da",
      "metadata": {},
      "source": [
        "# Preparing the LISA Traffic Light Dataset\n",
        "\n",
        "This notebook will guide you through the following steps:\n",
        "1.  **Imports and Setup**\n",
        "2.  **Consolidating and Converting Annotations** from the original LISA format (``frameAnnotationsBOX.csv`` files in a specific folder structure) to a single, standardized CSV file (``all_annotations.csv``).\n",
        "    * Copying images from the raw location to the ``PROCESSED_IMAGES_DIR_FRCNN_SSD`` folder while preserving the structure.\n",
        "    * CSV Format: ``filename,xmin,ymin,xmax,ymax,label,period``.\n",
        "    * ``filename`` will be the relative path to the image from the main image directory (e.g., ``daySequence1/frames/frame_0000.jpg``).\n",
        "3.  **Splitting the Consolidated CSV Annotations** into ``train``, ``val``, and ``test`` sets.\n",
        "4.  **Converting Annotations to YOLO Format** (.txt for each frame) and organizing the folder structure for YOLO."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea1cc971",
      "metadata": {},
      "source": [
        "## 0. Imports and settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5c1ebbe",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import glob \n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "# --- CONFIGURATION PATHS ---\n",
        "LISA_RAW_DATA_ROOT = \"../dataset/lisa_traffic_light_dataset_raw/\" \n",
        "LISA_ANNOTATIONS_BASE_DIR = os.path.join(LISA_RAW_DATA_ROOT, \"Annotations\", \"Annotations\")\n",
        "\n",
        "PROCESSED_DATA_ROOT_FRCNN_SSD = \"../dataset/lisa_traffic_light_dataset/\"\n",
        "PROCESSED_IMAGES_DIR_FRCNN_SSD = os.path.join(PROCESSED_DATA_ROOT_FRCNN_SSD, \"images\") \n",
        "PROCESSED_ANNOTATIONS_DIR_FRCNN_SSD = os.path.join(PROCESSED_DATA_ROOT_FRCNN_SSD, \"annotations\")\n",
        "\n",
        "YOLO_DATA_ROOT = \"../dataset/lisa_yolo_formatted/\"\n",
        "\n",
        "os.makedirs(PROCESSED_IMAGES_DIR_FRCNN_SSD, exist_ok=True)\n",
        "os.makedirs(PROCESSED_ANNOTATIONS_DIR_FRCNN_SSD, exist_ok=True)\n",
        "os.makedirs(YOLO_DATA_ROOT, exist_ok=True)\n",
        "\n",
        "# --- MAPPING LABELS ---\n",
        "LISA_TO_COMMON_LABEL_MAP = {\n",
        "    \"stop\": \"stop\", \"stopLeft\": \"stop\", \"stopRight\": \"stop\", \"stopAhead\": \"stop\",\n",
        "    \"go\": \"go\", \"goLeft\": \"go\", \"goRight\": \"go\", \"goAhead\": \"go\",\n",
        "    \"warning\": \"warning\", \"warningLeft\": \"warning\", \"warningRight\": \"warning\", \"warningAhead\": \"warning\",\n",
        "    \"off\": \"off\" \n",
        "}\n",
        "\n",
        "COMMON_TO_YOLO_CLASS_ID_MAP = {'go': 0, 'stop': 1, 'warning': 2, 'off': 3}\n",
        "\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.15\n",
        "TEST_RATIO = 0.15 \n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0523eb53",
      "metadata": {},
      "source": [
        "## 1. Consolidation and Converting Annotations to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3dd6485",
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_annotation_files(root_dir, filename_to_find=\"frameAnnotationsBOX.csv\"):\n",
        "    \"\"\"Recursively finds all files with the given name in the given directory.\"\"\"\n",
        "    found_files = []\n",
        "    for dirpath, _, filenames in os.walk(root_dir):\n",
        "        for f_name in filenames:\n",
        "            if f_name == filename_to_find:\n",
        "                found_files.append(os.path.join(dirpath, f_name))\n",
        "    return found_files\n",
        "\n",
        "def consolidate_lisa_annotations_and_copy_images(annotations_search_root,\n",
        "                                                 raw_data_images_root,\n",
        "                                                 processed_images_output_root,\n",
        "                                                 output_csv_path):\n",
        "    all_annotations_list = []\n",
        "    copied_image_count = 0\n",
        "    processed_annotation_files_count = 0\n",
        "    total_objects_annotated = 0\n",
        "\n",
        "    print(f\"Searching {annotations_search_root} for frameAnnotationsBOX.csv files...\")\n",
        "\n",
        "    if not os.path.exists(annotations_search_root):\n",
        "        print(f\"ERROR: Base path for annotations {annotations_search_root} does not exist!\")\n",
        "        return\n",
        "\n",
        "    annotation_file_paths = find_annotation_files(annotations_search_root, \"frameAnnotationsBOX.csv\")\n",
        "\n",
        "    if not annotation_file_paths:\n",
        "        print(f\"No frameAnnotationsBOX.csv files found in {annotations_search_root} and its subfolders.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(annotation_file_paths)} annotation files to process.\")\n",
        "\n",
        "    for annotation_file_path_raw in annotation_file_paths:\n",
        "        annotation_file_path = os.path.normpath(annotation_file_path_raw)\n",
        "        print(f\"  Processing annotation file: {annotation_file_path}\")\n",
        "        processed_annotation_files_count += 1\n",
        "        try:\n",
        "            df_seq = pd.read_csv(annotation_file_path, sep=';')\n",
        "\n",
        "            required_cols_lisa = ['Filename', 'Annotation tag', 'Upper left corner X', 'Upper left corner Y', 'Lower right corner X', 'Lower right corner Y']\n",
        "            if not all(col in df_seq.columns for col in required_cols_lisa):\n",
        "                print(f\"    WARNING: Missing standard LISA columns in {annotation_file_path}. Skipping file. Columns: {df_seq.columns.tolist()}\")\n",
        "                continue\n",
        "\n",
        "            annotation_file_dir = os.path.dirname(annotation_file_path)\n",
        "            relative_path_of_annotations_dir = os.path.relpath(annotation_file_dir, annotations_search_root)\n",
        "            relative_path_of_annotations_dir = os.path.normpath(relative_path_of_annotations_dir).replace('\\\\', '/')\n",
        "\n",
        "            period_parts = relative_path_of_annotations_dir.lower().split('/')\n",
        "            period = \"unknown\"\n",
        "            if any(\"day\" in part for part in period_parts): period = \"day\"\n",
        "            elif any(\"night\" in part for part in period_parts): period = \"night\"\n",
        "            if period == \"unknown\": print(f\"    WARNING: Could not determine time of day for {relative_path_of_annotations_dir}.\")\n",
        "\n",
        "            path_components_from_annotations_dir = [comp for comp in relative_path_of_annotations_dir.split('/') if comp]\n",
        "            \n",
        "            candidate_image_folders = []\n",
        "            \n",
        "            # Change specific structures based on the annotations directory\n",
        "            if len(path_components_from_annotations_dir) > 0:\n",
        "                cand1_path = os.path.join(raw_data_images_root,\n",
        "                                            path_components_from_annotations_dir[0],\n",
        "                                            relative_path_of_annotations_dir,\n",
        "                                            \"frames\")\n",
        "                candidate_image_folders.append(os.path.normpath(cand1_path))\n",
        "\n",
        "            innermost_folder_name_from_annotations = path_components_from_annotations_dir[-1]\n",
        "            cand2_path = os.path.join(raw_data_images_root, \n",
        "                                        relative_path_of_annotations_dir, \n",
        "                                        innermost_folder_name_from_annotations, \n",
        "                                        \"frames\")\n",
        "            candidate_image_folders.append(os.path.normpath(cand2_path))\n",
        "\n",
        "            cand3_path = os.path.join(raw_data_images_root, \n",
        "                                        relative_path_of_annotations_dir, \n",
        "                                        \"frames\")\n",
        "            candidate_image_folders.append(os.path.normpath(cand3_path))\n",
        "            \n",
        "            cand4_path = os.path.join(raw_data_images_root, \n",
        "                                        relative_path_of_annotations_dir)\n",
        "            candidate_image_folders.append(os.path.normpath(cand4_path))\n",
        "\n",
        "\n",
        "            images_source_folder_for_sequence = None\n",
        "            for cand_path in candidate_image_folders:\n",
        "                if os.path.isdir(cand_path):\n",
        "                    if any(f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')) for f in os.listdir(cand_path)):\n",
        "                        images_source_folder_for_sequence = cand_path\n",
        "                        break\n",
        "            \n",
        "            if not images_source_folder_for_sequence:\n",
        "                print(f\"    WARNING: Could not find image folder for annotation sequence {relative_path_of_annotations_dir}.\")\n",
        "                print(f\"       Checked candidate paths (normalized):\")\n",
        "                for cp_idx, cp in enumerate(candidate_image_folders):\n",
        "                     print(f\"         {cp_idx+1}. {cp}\")\n",
        "                print(f\"    Skipping annotations from file {annotation_file_path}.\")\n",
        "                continue\n",
        "            \n",
        "            for _, row in df_seq.iterrows():\n",
        "                original_frame_name_from_csv = str(row['Filename']).split('/')[-1]\n",
        "                raw_label = row['Annotation tag']\n",
        "                common_label = LISA_TO_COMMON_LABEL_MAP.get(raw_label)\n",
        "\n",
        "                if common_label is None: continue\n",
        "\n",
        "                source_image_path = os.path.join(images_source_folder_for_sequence, original_frame_name_from_csv)\n",
        "                source_image_path = os.path.normpath(source_image_path)\n",
        "\n",
        "                if not os.path.exists(source_image_path):\n",
        "                    continue\n",
        "                \n",
        "                path_to_frames_folder_relative_to_raw_root = os.path.relpath(images_source_folder_for_sequence, raw_data_images_root)\n",
        "                path_to_frames_folder_relative_to_raw_root = os.path.normpath(path_to_frames_folder_relative_to_raw_root).replace('\\\\', '/')\n",
        "                \n",
        "                dest_relative_image_path = os.path.join(path_to_frames_folder_relative_to_raw_root, original_frame_name_from_csv)\n",
        "                dest_relative_image_path = os.path.normpath(dest_relative_image_path).replace('\\\\', '/')\n",
        "                \n",
        "                dest_image_full_path = os.path.join(processed_images_output_root, dest_relative_image_path)\n",
        "                dest_image_full_path = os.path.normpath(dest_image_full_path)\n",
        "\n",
        "                os.makedirs(os.path.dirname(dest_image_full_path), exist_ok=True)\n",
        "\n",
        "                if not os.path.exists(dest_image_full_path):\n",
        "                    shutil.copy2(source_image_path, dest_image_full_path)\n",
        "                    copied_image_count +=1\n",
        "                \n",
        "                all_annotations_list.append({\n",
        "                    'filename': dest_relative_image_path,\n",
        "                    'xmin': row['Upper left corner X'],\n",
        "                    'ymin': row['Upper left corner Y'],\n",
        "                    'xmax': row['Lower right corner X'],\n",
        "                    'ymax': row['Lower right corner Y'],\n",
        "                    'label': common_label,\n",
        "                    'period': period\n",
        "                })\n",
        "                total_objects_annotated +=1\n",
        "\n",
        "        except pd.errors.EmptyDataError:\n",
        "            print(f\"    INFO: File {annotation_file_path} is empty. Skipping.\")\n",
        "        except Exception as e:\n",
        "            print(f\"    ERROR during processing of file {annotation_file_path}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "    \n",
        "    if not all_annotations_list:\n",
        "        print(\"No valid annotations found to process.\")\n",
        "        return\n",
        "\n",
        "    final_df = pd.DataFrame(all_annotations_list)\n",
        "    \n",
        "    for col in ['xmin', 'ymin', 'xmax', 'ymax']:\n",
        "        final_df[col] = pd.to_numeric(final_df[col], errors='coerce')\n",
        "    final_df.dropna(subset=['xmin', 'ymin', 'xmax', 'ymax', 'label', 'filename'], inplace=True)\n",
        "    final_df = final_df[(final_df['xmax'] > final_df['xmin']) & (final_df['ymax'] > final_df['ymin'])]\n",
        "\n",
        "    final_df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Saved consolidated annotations to: {output_csv_path} ({len(final_df['filename'].unique())} unique images, {total_objects_annotated} objects).\")\n",
        "    print(f\"Processed {processed_annotation_files_count} annotation files.\")\n",
        "    print(f\"Copied {copied_image_count} new images to {processed_images_output_root}.\")\n",
        "\n",
        "consolidated_csv_file = os.path.join(PROCESSED_ANNOTATIONS_DIR_FRCNN_SSD, \"all_annotations.csv\")\n",
        "\n",
        "consolidate_lisa_annotations_and_copy_images(\n",
        "    LISA_ANNOTATIONS_BASE_DIR, \n",
        "    LISA_RAW_DATA_ROOT,      \n",
        "    PROCESSED_IMAGES_DIR_FRCNN_SSD, \n",
        "    consolidated_csv_file\n",
        ")\n",
        "print(\"Consolidation of annotations and copying of images completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d682553c",
      "metadata": {},
      "source": [
        "## 2. Splitting Consolidated Annotations into Train, Val, Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eb8da8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def perform_train_val_test_split(consolidated_csv, output_dir, \n",
        "                                     train_r=0.7, val_r=0.15, random_s=42):\n",
        "    if not os.path.exists(consolidated_csv):\n",
        "        print(f\"File {consolidated_csv} does not exist. Cannot perform split.\")\n",
        "        return\n",
        "    df = pd.read_csv(consolidated_csv)\n",
        "    if df.empty: print(f\"File {consolidated_csv} is empty. Cannot perform split.\"); return\n",
        "    unique_files = df['filename'].unique()\n",
        "    if len(unique_files) < 3:\n",
        "        print(f\"Too few unique files ({len(unique_files)}) to split. All will go to 'train'.\")\n",
        "        df.to_csv(os.path.join(output_dir, \"train_annotations.csv\"), index=False)\n",
        "        pd.DataFrame(columns=df.columns).to_csv(os.path.join(output_dir, \"val_annotations.csv\"), index=False)\n",
        "        pd.DataFrame(columns=df.columns).to_csv(os.path.join(output_dir, \"test_annotations.csv\"), index=False)\n",
        "        return\n",
        "    current_test_r = 1.0 - train_r - val_r\n",
        "    if current_test_r < -1e-5: \n",
        "        print(f\"Sum of train_r ({train_r}) and val_r ({val_r}) exceeds 1.0. Correcting proportions.\")\n",
        "        if train_r < 1.0: val_r = 1.0 - train_r; current_test_r = 0.0\n",
        "        else: val_r = 0.0; current_test_r = 0.0\n",
        "        print(f\"New proportions: train={train_r}, val={val_r}, test={current_test_r}\")\n",
        "    elif abs(current_test_r) < 1e-5 : current_test_r = 0.0\n",
        "    train_filenames, remaining_filenames = train_test_split(unique_files, test_size=(val_r + current_test_r), random_state=random_s, shuffle=True)\n",
        "    df_train = df[df['filename'].isin(train_filenames)]\n",
        "    df_train.to_csv(os.path.join(output_dir, \"train_annotations.csv\"), index=False)\n",
        "    print(f\"Training set: {len(df_train['filename'].unique())} images, {len(df_train)} annotations.\")\n",
        "    if remaining_filenames.size > 0 and (val_r > 1e-5 or current_test_r > 1e-5):\n",
        "        if current_test_r < 1e-5 or val_r < 1e-5 or len(remaining_filenames) < 2:\n",
        "            if val_r > 1e-5: val_filenames = remaining_filenames; test_filenames = np.array([])\n",
        "            else: test_filenames = remaining_filenames; val_filenames = np.array([])\n",
        "        else:\n",
        "            relative_test_ratio_for_split = current_test_r / (val_r + current_test_r)\n",
        "            val_filenames, test_filenames = train_test_split(remaining_filenames, test_size=relative_test_ratio_for_split, random_state=random_s, shuffle=True)\n",
        "        df_val = df[df['filename'].isin(val_filenames)]\n",
        "        df_test = df[df['filename'].isin(test_filenames)]\n",
        "        df_val.to_csv(os.path.join(output_dir, \"val_annotations.csv\"), index=False)\n",
        "        df_test.to_csv(os.path.join(output_dir, \"test_annotations.csv\"), index=False)\n",
        "        print(f\"Validation set: {len(df_val['filename'].unique())} images, {len(df_val)} annotations.\")\n",
        "        print(f\"Test set: {len(df_test['filename'].unique())} images, {len(df_test)} annotations.\")\n",
        "    else:\n",
        "        print(\"No data for validation and/or test set after split.\")\n",
        "        pd.DataFrame(columns=df.columns).to_csv(os.path.join(output_dir, \"val_annotations.csv\"), index=False)\n",
        "        pd.DataFrame(columns=df.columns).to_csv(os.path.join(output_dir, \"test_annotations.csv\"), index=False)\n",
        "\n",
        "perform_train_val_test_split(consolidated_csv_file, PROCESSED_ANNOTATIONS_DIR_FRCNN_SSD, \n",
        "                                 train_r=TRAIN_RATIO, val_r=VAL_RATIO, random_s=RANDOM_STATE)\n",
        "print(\"Splitting into train/val/test sets (CSV) completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47fc60a8",
      "metadata": {},
      "source": [
        "## 3. Converting Annotations to YOLO Format and Organizing Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb1530d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_csv_to_yolo_and_copy_images(source_csv_path, \n",
        "                                            processed_images_root,\n",
        "                                            yolo_target_root,\n",
        "                                            split_name):\n",
        "    if not os.path.exists(source_csv_path): \n",
        "        print(f\"CSV file {source_csv_path} does not exist. Skipping YOLO conversion for {split_name}.\")\n",
        "        return\n",
        "    \n",
        "    df = pd.read_csv(source_csv_path)\n",
        "    if df.empty: \n",
        "        print(f\"CSV file {source_csv_path} is empty. Skipping YOLO conversion for {split_name}.\")\n",
        "        return\n",
        "\n",
        "    yolo_img_dir = os.path.join(yolo_target_root, \"images\", split_name)\n",
        "    yolo_lbl_dir = os.path.join(yolo_target_root, \"labels\", split_name)\n",
        "    os.makedirs(yolo_img_dir, exist_ok=True)\n",
        "    os.makedirs(yolo_lbl_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"YOLO conversion for {split_name}...\")\n",
        "    \n",
        "    for img_relative_path_from_csv, group in df.groupby('filename'):\n",
        "        full_source_img_path = os.path.join(processed_images_root, img_relative_path_from_csv)\n",
        "        full_source_img_path = os.path.normpath(full_source_img_path)\n",
        "\n",
        "        if not os.path.exists(full_source_img_path):\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            with Image.open(full_source_img_path) as img:\n",
        "                img_width, img_height = img.size\n",
        "        except Exception as e:\n",
        "            print(f\"  WARNING: Could not open image {full_source_img_path}: {e}. Skipping for YOLO.\")\n",
        "            continue\n",
        "\n",
        "        flat_img_name_base = img_relative_path_from_csv.replace('/', '_').replace('\\\\', '_')\n",
        "        \n",
        "        yolo_img_dest_path = os.path.join(yolo_img_dir, flat_img_name_base)\n",
        "        yolo_img_dest_path = os.path.normpath(yolo_img_dest_path)\n",
        "\n",
        "        if not os.path.exists(yolo_img_dest_path):\n",
        "            try:\n",
        "                shutil.copy2(full_source_img_path, yolo_img_dest_path)\n",
        "            except FileNotFoundError:\n",
        "                print(f\"  Copy ERROR: Could not copy {full_source_img_path} to {yolo_img_dest_path}\")\n",
        "                print(f\"    img_relative_path_from_csv: {img_relative_path_from_csv}\")\n",
        "                print(f\"    flat_img_name_base: {flat_img_name_base}\")\n",
        "                continue\n",
        "        \n",
        "        yolo_label_filename = os.path.splitext(flat_img_name_base)[0] + \".txt\"\n",
        "        yolo_label_file_path = os.path.join(yolo_lbl_dir, yolo_label_filename)\n",
        "        yolo_label_file_path = os.path.normpath(yolo_label_file_path)\n",
        "        \n",
        "        with open(yolo_label_file_path, 'w') as f_yolo:\n",
        "            for _, row in group.iterrows():\n",
        "                class_id = COMMON_TO_YOLO_CLASS_ID_MAP.get(row['label'])\n",
        "                if class_id is None:\n",
        "                    continue\n",
        "                \n",
        "                xmin, ymin, xmax, ymax = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n",
        "                \n",
        "                if not (xmax > xmin and ymax > ymin and xmin >= 0 and ymin >= 0 and xmax <= img_width and ymax <= img_height):\n",
        "                    continue\n",
        "\n",
        "                x_center = (xmin + xmax) / 2.0\n",
        "                y_center = (ymin + ymax) / 2.0\n",
        "                box_width = xmax - xmin\n",
        "                box_height = ymax - ymin\n",
        "\n",
        "                x_center_norm = x_center / img_width\n",
        "                y_center_norm = y_center / img_height\n",
        "                box_width_norm = box_width / img_width\n",
        "                box_height_norm = box_height / img_height\n",
        "                \n",
        "                if not (0 <= x_center_norm <= 1 and 0 <= y_center_norm <= 1 and 0 <= box_width_norm <= 1 and 0 <= box_height_norm <= 1):\n",
        "                    continue\n",
        "\n",
        "                f_yolo.write(f\"{class_id} {x_center_norm:.6f} {y_center_norm:.6f} {box_width_norm:.6f} {box_height_norm:.6f}\\n\")\n",
        "    \n",
        "    print(f\"Finished YOLO conversion for {split_name}.\")\n",
        "\n",
        "# --- Run YOLO format conversion ---\n",
        "for split in ['train', 'val', 'test']:\n",
        "    csv_file_for_split = os.path.join(PROCESSED_ANNOTATIONS_DIR_FRCNN_SSD, f\"{split}_annotations.csv\")\n",
        "    if os.path.exists(csv_file_for_split):\n",
        "        convert_csv_to_yolo_and_copy_images(csv_file_for_split,\n",
        "                                              PROCESSED_IMAGES_DIR_FRCNN_SSD, \n",
        "                                              YOLO_DATA_ROOT,\n",
        "                                              split_name=split)\n",
        "    else:\n",
        "        print(f\"File {csv_file_for_split} does not exist, skipping YOLO data creation for {split}.\")\n",
        "print(\"\\nYOLO formatted data preparation completed.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
